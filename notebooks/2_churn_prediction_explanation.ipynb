{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainable AI (XAI) Demo: Customer Churn Prediction\n",
    "\n",
    "This notebook demonstrates how to use SHAP to interpret an `XGBoost` model trained on a synthetic customer churn dataset.\n",
    "\n",
    "**Objective:** Understand the key drivers behind customer churn according to our model.\n",
    "\n",
    "**Workflow:**\n",
    "1. **Load and Preprocess Data:** Import and clean the churn data using our custom functions.\n",
    "2. **Train Model:** Train an XGBoost model.\n",
    "3. **Explain with SHAP:** Generate global and local SHAP explanations to interpret the model's behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import shap\n",
    "\n",
    "# Add the src directory to the Python path\n",
    "sys.path.append('../src')\n",
    "\n",
    "from data_preprocessing import load_data, preprocess_churn_data\n",
    "from model_training import train_xgb_classifier\n",
    "from explainability import get_shap_explainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data('../data/churn_synthetic.csv')\n",
    "X, y = preprocess_churn_data(df)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train the XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, X_test, y_test = train_xgb_classifier(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Explain the Model with SHAP\n",
    "\n",
    "We will generate two types of SHAP plots:\n",
    "- **Summary Plot (Bar):** Shows the average impact of each feature on the model's output magnitude (global importance).\n",
    "- **Summary Plot (Dot):** Shows not only the importance but also the direction of the impact for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer, shap_values = get_shap_explainer(model, X_test)\n",
    "\n",
    "# SHAP Bar Plot (Global Importance)\n",
    "print(\"SHAP Summary Bar Plot\")\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP Dot Plot (Directional Importance)\n",
    "print(\"SHAP Summary Dot Plot\")\n",
    "shap.summary_plot(shap_values, X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}